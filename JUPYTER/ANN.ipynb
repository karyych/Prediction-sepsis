{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Datasets\\\\sepsis-predict.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_drop = [\"Unnamed: 0.1\", \"Unnamed: 0\", \"timestamp\"]\n",
    "data.drop(columns_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"SOFA\", axis=1).values\n",
    "y = data[\"SOFA\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Sequential()\n",
    "ann.add(Dense(units=12, activation=\"relu\", input_dim=X_train.shape[1]))\n",
    "ann.add(Dense(units=6, activation=\"relu\"))\n",
    "ann.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer=Adam(), loss=\"mse\", metrics=[\"mae\", \"mse\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Предсказания модели на обучающем и тестовом наборах данных\n",
    "        train_pred = self.model.predict(X_train)\n",
    "        test_pred = self.model.predict(X_test)\n",
    "\n",
    "        # Вычисление accuracy\n",
    "        train_acc = accuracy_score(y_train, np.round(train_pred))\n",
    "        test_acc = accuracy_score(y_test, np.round(test_pred))\n",
    "\n",
    "        # Вычисление MSE и MAE\n",
    "        train_mse = mean_squared_error(y_train, train_pred)\n",
    "        test_mse = mean_squared_error(y_test, test_pred)\n",
    "        train_mae = mean_absolute_error(y_train, train_pred)\n",
    "        test_mae = mean_absolute_error(y_test, test_pred)\n",
    "\n",
    "        # Вывод метрик\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}/{self.params[\"epochs\"]}, '\n",
    "            f'Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}, '\n",
    "            f'Train MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}, '\n",
    "            f'Train MAE: {train_mae:.4f}, Test MAE: {test_mae:.4f}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели с использованием созданного обратного вызова\n",
    "ann.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[MetricsCallback(), EarlyStopping(monitor=\"val_loss\", patience=4)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания на обучающем и тестовом наборах данных\n",
    "y_train_pred = ann.predict(X_train)\n",
    "y_test_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет метрик на обучающем наборе\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет метрик на тестовом наборе\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод метрик\n",
    "print(\"Метрики на обучающем наборе:\")\n",
    "print(\"Mean Squared Error (MSE):\", train_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", train_mae)\n",
    "print(\"R^2 Score:\", train_r2)\n",
    "print(\"\\nМетрики на тестовом наборе:\")\n",
    "print(\"Mean Squared Error (MSE):\", test_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", test_mae)\n",
    "print(\"R^2 Score:\", test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ann.predict(X_test)\n",
    "predictions_df = pd.DataFrame(np.ravel(predictions), columns=[\"Predictions\"])\n",
    "comparison_df = pd.concat(\n",
    "    [pd.DataFrame(y_test, columns=[\"Real Values\"]), predictions_df], axis=1\n",
    ")\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация реальных значений и предсказанных значений\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    comparison_df.index, comparison_df[\"Real Values\"], label=\"Real Values\", marker=\"o\"\n",
    ")\n",
    "plt.plot(\n",
    "    comparison_df.index, comparison_df[\"Predictions\"], label=\"Predictions\", marker=\"x\"\n",
    ")\n",
    "plt.title(\"Comparison of Real Values and Predictions\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
